{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "relation_ids = {\n",
    "    \"Other\": 0,\n",
    "    \"Cause-Effect(e1,e2)\": 1,\n",
    "    \"Instrument-Agency(e1,e2)\": 2,\n",
    "    \"Product-Producer(e1,e2)\": 3,\n",
    "    \"Content-Container(e1,e2)\": 4,\n",
    "    \"Entity-Origin(e1,e2)\": 5,\n",
    "    \"Entity-Destination(e1,e2)\": 6,\n",
    "    \"Component-Whole(e1,e2)\": 7,\n",
    "    \"Member-Collection(e1,e2)\": 8,\n",
    "    \"Message-Topic(e1,e2)\": 9,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from TRAIN_FILE.txt and saving preprocessed files to .\\train_%s_1000.csv\n",
      "Loading data from TRAIN_FILE.txt and saving preprocessed files to .\\train_%s_2000.csv\n",
      "Loading data from TRAIN_FILE.txt and saving preprocessed files to .\\train_%s_4000.csv\n",
      "Loading data from TRAIN_FILE.txt and saving preprocessed files to .\\train_%s_8000.csv\n",
      "Loading data from TEST_FILE_FULL.txt and saving preprocessed files to .\\test_%s.csv\n"
     ]
    }
   ],
   "source": [
    "from os.path import join\n",
    "\n",
    "def find_between(s, a, b):\n",
    "    return s.split(a)[1].split(b)[0].strip().replace(\" \", \"\")\n",
    "\n",
    "def preprocess_data(path, out_path, save_opposites=False, num_rel=None):\n",
    "    print(\"Loading data from\", path, \"and saving preprocessed files to\", out_path)\n",
    "    in_file = open(path)\n",
    "\n",
    "    relation_files = {}\n",
    "    for relation_id in relation_ids:\n",
    "        relation_files[relation_id] = open(\n",
    "            out_path % relation_id, \"w\", encoding=\"utf-8\")\n",
    "\n",
    "    while True:\n",
    "        line = in_file.readline()\n",
    "\n",
    "        if num_rel is not None:\n",
    "            num_rel -= 1\n",
    "            if num_rel < 0:\n",
    "                break\n",
    "\n",
    "        if not line:\n",
    "            break\n",
    "\n",
    "        text_id, text = line.split(\"\\t\")\n",
    "\n",
    "        word_a = find_between(text, \"<e1>\", \"</e1>\")\n",
    "        word_b = find_between(text, \"<e2>\", \"</e2>\")\n",
    "\n",
    "        relation = in_file.readline().strip()\n",
    "        comment = in_file.readline()\n",
    "\n",
    "        # Swap words if the relation-order is not word_1, word_2\n",
    "        if relation != \"Other\" and not \"(e1,e2)\" in relation:\n",
    "            word_a, word_b = word_b, word_a\n",
    "            relation = relation.replace(\"(e2,e1)\", \"(e1,e2)\")\n",
    "\n",
    "        word_a = word_a.replace(\" \", \"_\").lower()\n",
    "        word_b = word_b.replace(\" \", \"_\").lower()\n",
    "\n",
    "        relation_files[relation].write(\"%s %s\\n\" % (word_a, word_b))\n",
    "\n",
    "        if save_opposites:\n",
    "            relation_files[\"Other\"].write(\"%s %s\\n\" % (word_b, word_a))\n",
    "\n",
    "        # New line\n",
    "        in_file.readline()\n",
    "    \n",
    "train_file = \"TRAIN_FILE.txt\"\n",
    "test_file = \"TEST_FILE_FULL.txt\"\n",
    "out_path = \".\"\n",
    "\n",
    "# Train\n",
    "\n",
    "preprocess_data(train_file, join(\n",
    "    out_path, \"train_%s_1000.csv\"), num_rel=1000)\n",
    "preprocess_data(train_file, join(\n",
    "    out_path, \"train_%s_2000.csv\"), num_rel=2000)\n",
    "preprocess_data(train_file, join(\n",
    "    out_path, \"train_%s_4000.csv\"), num_rel=4000)\n",
    "preprocess_data(train_file, join(\n",
    "    out_path, \"train_%s_8000.csv\"), num_rel=8000)\n",
    "\n",
    "# Test\n",
    "preprocess_data(test_file, join(out_path, \"test_%s.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing relations at train_Cause-Effect(e1,e2)_8000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1003it [00:01, 711.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing relations at train_Component-Whole(e1,e2)_8000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "941it [00:00, 3034.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing relations at train_Content-Container(e1,e2)_8000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "540it [00:00, 3120.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing relations at train_Entity-Destination(e1,e2)_8000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "845it [00:00, 3001.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing relations at train_Entity-Origin(e1,e2)_8000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "716it [00:00, 3254.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing relations at train_Instrument-Agency(e1,e2)_8000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "504it [00:00, 3251.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing relations at train_Member-Collection(e1,e2)_8000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "690it [00:00, 3121.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing relations at train_Message-Topic(e1,e2)_8000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "634it [00:00, 2934.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing relations at train_Other_8000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1410it [00:00, 3074.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing relations at train_Product-Producer(e1,e2)_8000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "717it [00:00, 3334.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Relations statistics\n",
      "\t 8000 total relations\n",
      "\t 8000 found relations (100.00%)\n",
      "\t 0 invalid relations (0.00%)\n",
      "\t 0 unavailable relations (0.00%)\n",
      "Relation embeddings count: 7664\n",
      "Saving embeddings to relations_train_8000.h5\n",
      "Saving labels to labels_train_8000.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\pandas\\io\\pytables.py:280: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->axis1] [items->None]\n",
      "\n",
      "  f(store)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing relations at test_Cause-Effect(e1,e2).csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "328it [00:00, 2954.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing relations at test_Component-Whole(e1,e2).csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "312it [00:00, 3318.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing relations at test_Content-Container(e1,e2).csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192it [00:00, 3199.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing relations at test_Entity-Destination(e1,e2).csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "292it [00:00, 3139.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing relations at test_Entity-Origin(e1,e2).csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "258it [00:00, 3089.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing relations at test_Instrument-Agency(e1,e2).csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [00:00, 3088.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing relations at test_Member-Collection(e1,e2).csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "233it [00:00, 3085.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing relations at test_Message-Topic(e1,e2).csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "261it [00:00, 3069.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing relations at test_Other.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "454it [00:00, 2828.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing relations at test_Product-Producer(e1,e2).csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:00, 3207.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Relations statistics\n",
      "\t 2717 total relations\n",
      "\t 2717 found relations (100.00%)\n",
      "\t 0 invalid relations (0.00%)\n",
      "\t 0 unavailable relations (0.00%)\n",
      "Relation embeddings count: 2671\n",
      "Saving embeddings to relations_test.h5\n",
      "Saving labels to labels_test.h5\n"
     ]
    }
   ],
   "source": [
    "from ontokom.embeddings import create_relation_dataset, DataFrameEmbeddings\n",
    "from glob import glob\n",
    "\n",
    "embeddings = DataFrameEmbeddings(\"embeddings_acm_wiki_glove_300.h5\")\n",
    "embeddings.load()\n",
    "\n",
    "relation_paths_train = glob(\"train_*_8000.csv\")\n",
    "relation_paths_test = glob(\"test_*.csv\")\n",
    "\n",
    "create_relation_dataset(embeddings, \"relations_train_8000.h5\", \"labels_train_8000.h5\", relation_paths_train,\n",
    "                        unknown_word=\"<unk>\")\n",
    "create_relation_dataset(embeddings, \"relations_test.h5\", \"labels_test.h5\", relation_paths_test,\n",
    "                        unknown_word=\"<unk>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_5 (Reshape)          (None, 2, 300, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 147, 64)        960       \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 1, 147, 64)        256       \n",
      "_________________________________________________________________\n",
      "reshape_6 (Reshape)          (None, 147, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 74, 128)           41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 74, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 37, 256)           164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 37, 256)           1024      \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 19, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 19, 256)           1024      \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 10, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 10, 256)           1024      \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 5, 256)            327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 5, 256)            1024      \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 3, 256)            327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 3, 256)            1024      \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 1, 256)            196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 1, 256)            1024      \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,724,234\n",
      "Trainable params: 1,720,778\n",
      "Non-trainable params: 3,456\n",
      "_________________________________________________________________\n",
      "None\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.86      0.74       325\n",
      "          1       0.69      0.66      0.67       302\n",
      "          2       0.60      0.61      0.61       183\n",
      "          3       0.39      0.38      0.38       292\n",
      "          4       0.40      0.51      0.44       251\n",
      "          5       0.56      0.40      0.46       156\n",
      "          6       0.71      0.70      0.71       226\n",
      "          7       0.67      0.72      0.69       261\n",
      "          8       0.40      0.29      0.34       450\n",
      "          9       0.63      0.63      0.63       225\n",
      "\n",
      "avg / total       0.56      0.56      0.56      2671\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ontokom.classification import RelationClassifier, load_relations, load_labels\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "train_relations = load_relations(\"relations_train_8000.h5\")\n",
    "train_labels = load_labels(\"labels_train_8000.h5\")\n",
    "assert train_relations.shape[0] == train_labels.shape[0]\n",
    "\n",
    "test_relations = load_relations(\"relations_test.h5\")\n",
    "test_labels = load_labels(\"labels_test.h5\")\n",
    "test_labels = np.argmax(test_labels, 1)\n",
    "assert test_relations.shape[0] == test_labels.shape[0]\n",
    "\n",
    "classifier = RelationClassifier()\n",
    "classifier.new(train_relations.shape[1], train_labels.shape[1], one_hot=True,\n",
    "               filters=64, max_filters=256,\n",
    "               optimizer=\"rmsprop\", learn_rate=0.01,\n",
    "               dropout=0.0, kernel_size=5)\n",
    "\n",
    "classifier.train(train_relations, train_labels,\n",
    "                 epochs=20, validation_split=0, verbose=0)\n",
    "\n",
    "predicted_labels = np.argmax(classifier.predict(test_relations), 1)\n",
    "\n",
    "print(classification_report(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
